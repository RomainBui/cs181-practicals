{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Romain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "- A lot of unsuccesfull execution of task, might indicates 'trying to find a breach'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Classical libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'Data/train/0a8e69f80f39b18a78ca7B778a4efb029e7b42fbf.Zbot.xml'\n",
    "tree = ET.parse(path)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def XML_get(root, element, attrib_name=''):\n",
    "    res = []\n",
    "    if attrib_name != '':\n",
    "        for t in root.iter(element):\n",
    "            try: \n",
    "                res.append(t.attrib[attrib_name])\n",
    "            except:\n",
    "                continue\n",
    "                #res.append(None)\n",
    "    else:\n",
    "        for t in root.iter(element):\n",
    "            try:\n",
    "                res.append(t.attrib)\n",
    "            except:\n",
    "                continue\n",
    "                #res.append(None)\n",
    "    return res\n",
    "\n",
    "### Get some potential features\n",
    "\n",
    "    # Load DLL\n",
    "load_dll_files              = XML_get(root, 'load_dll',   'filename')\n",
    "\n",
    "    # VM_Protect\n",
    "vm_protect_target           = XML_get(root, 'vm_protect', 'target')\n",
    "vm_protect_protect          = XML_get(root, 'vm_protect', 'protect')\n",
    "vm_protect_behavior         = XML_get(root, 'vm_protect', 'behavior')\n",
    "\n",
    "    # Open Key\n",
    "open_key_key                = XML_get(root, 'open_key', 'key')\n",
    "\n",
    "    # Process\n",
    "process_filename            = XML_get(root, 'process', 'filename')\n",
    "process_filesize            = XML_get(root, 'process', 'filesize')\n",
    "process_username            = XML_get(root, 'process', 'username')\n",
    "process_applicationtype     = XML_get(root, 'process', 'applicationtype')\n",
    "process_terminationreason   = XML_get(root, 'process', 'terminationreason')\n",
    "\n",
    "    # Set Files Attributes\n",
    "set_file_attributes_srcfile = XML_get(root, 'set_file_attributes', 'srcfile')\n",
    "\n",
    "    # Open File\n",
    "open_file_filetype      = XML_get(root, 'open_file', 'filetype')\n",
    "open_file_srcfile       = XML_get(root, 'open_file', 'srcfile')\n",
    "open_file_desiredaccess = XML_get(root, 'open_file', 'desiredaccess')\n",
    "\n",
    "    # Find the successes\n",
    "successes = []\n",
    "for t in root.findall(\".//*[@successful]\"):\n",
    "    successes.append(int(t.attrib['successful']))\n",
    "success_ratio = sum(successes) / float(len(successes))\n",
    "\n",
    "    # Kill Process\n",
    "kill_process = XML_get(root, 'kill_process', 'apifunction')\n",
    "\n",
    "\n",
    "def createFeatures(root):\n",
    "    load_dll_files = XML_get(root, 'load_dll',   'filename')\n",
    "    load_dll_files = [i.replace('\\\\', ' ') for i in load_dll_files]\n",
    "    vm_protect_target = XML_get(root, 'vm_protect', 'target')\n",
    "    vm_protect_protect = XML_get(root, 'vm_protect', 'protect')\n",
    "    vm_protect_behavior = XML_get(root, 'vm_protect', 'behavior')\n",
    "    open_key_key = XML_get(root, 'open_key', 'key')\n",
    "    \n",
    "    \n",
    "    res = np.concatenate([load_dll_files\n",
    "                         ])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NtTerminateProcess']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kill_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find all the tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tags = []\n",
    "for t in root.iter('all_section'):\n",
    "    for child in t.getchildren():\n",
    "        all_tags.append(child.tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(all_tags).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Features to the New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'Data/train/0a8e69f80f39b18a78ca7B778a4efb029e7b42fbf.Zbot.xml'\n",
    "tree = ET.parse(path)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loop on the data and create the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids_classes = []\n",
    "trees = []\n",
    "for fname in os.listdir('Data/train')[:300]:\n",
    "    if fname == '.DS_Store':\n",
    "        continue\n",
    "    id_str, clazz = fname.split('.')[:2]\n",
    "    ids_classes.append((id_str, clazz))\n",
    "    tree = ET.parse(os.path.join('Data/train', fname))\n",
    "    trees.append(tree)\n",
    "\n",
    "train_df = pd.DataFrame.from_records(ids_classes, columns=['id','class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_calls = ['processes','all_section','thread','process']\n",
    "docs = []\n",
    "for tree in trees:\n",
    "    calls = []\n",
    "    for ele in tree.iter():\n",
    "        if ele.tag not in not_calls:\n",
    "            calls.append(ele.tag)   \n",
    "    docs.append(calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(trees)):\n",
    "    docs[i].extend(createFeatures(trees[i].getroot()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### y management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df['class'].values\n",
    "def to_2class(classes):\n",
    "    return ['None' if label == 'None' else 'Mal' for label in classes] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TFIDF Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,10))\n",
    "tfidf = vectorizer.fit_transform([' '.join(doc) for doc in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_and_score(clf, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_preds = clf.predict(X_train)\n",
    "    print 'train accuracy: ' + str(metrics.accuracy_score(y_train, train_preds))\n",
    "    test_preds = clf.predict(X_test)\n",
    "    print 'validation accuracy: ' + str(metrics.accuracy_score(y_test, test_preds))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "_ = classify_and_score(lr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RFC(n_estimators=50)\n",
    "_ = classify_and_score(rfc, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 43.6 s, total: 2min 16s\n",
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ids_classes = []\n",
    "trees = []\n",
    "for fname in os.listdir('Data/test'):\n",
    "    if fname == '.DS_Store':\n",
    "        continue\n",
    "    id_str, clazz = fname.split('.')[:2]\n",
    "    ids_classes.append((id_str, clazz))\n",
    "    tree = ET.parse(os.path.join('Data/test', fname))\n",
    "    trees.append(tree)\n",
    "    \n",
    "    \n",
    "for fname in os.listdir('Data/train')[:300]:\n",
    "    if fname == '.DS_Store':\n",
    "        continue\n",
    "    id_str, clazz = fname.split('.')[:2]\n",
    "    ids_classes.append((id_str, clazz))\n",
    "    tree = ET.parse(os.path.join('Data/train', fname))\n",
    "    trees.append(tree)\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_records(ids_classes, columns=['id','class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "not_calls = ['processes','all_section','thread','process']\n",
    "docs = []\n",
    "for tree in trees:\n",
    "    calls = []\n",
    "    for ele in tree.iter():\n",
    "        if ele.tag not in not_calls:\n",
    "            calls.append(ele.tag)   \n",
    "    docs.append(calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(0,len(trees)):\n",
    "    docs[i].extend(createFeatures(trees[i].getroot()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "tfidf = vectorizer.fit_transform([' '.join(doc) for doc in docs])\n",
    "X = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ix  = (df['class'] == 'X')\n",
    "train_ix = (df['class'] != 'X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 1.0\n",
      "validation accuracy: 0.710526315789\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RFC(n_estimators=50)\n",
    "_ = classify_and_score(rfc, X.loc[train_ix], y[train_ix.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = rfc.predict(X.loc[test_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[test_ix, 'Prediction'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "malware_classes = [\"Agent\", \"AutoRun\", \"FraudLoad\", \"FraudPack\", \"Hupigon\", \"Krap\",\n",
    "           \"Lipler\", \"Magania\", \"None\", \"Poison\", \"Swizzor\", \"Tdss\",\n",
    "           \"VB\", \"Virut\", \"Zbot\"]\n",
    "\n",
    "malware_classes_dict = pd.DataFrame(malware_classes)\n",
    "malware_classes_dict.columns = ['Name']\n",
    "malware_classes_dict.loc[:, 'ID'] = malware_classes_dict.index.values \n",
    "malware_classes_dict.index = malware_classes_dict.Name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[test_ix, 'Prediction'] = df.loc[test_ix, 'Prediction'].apply(lambda x : malware_classes_dict.loc[x, 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[test_ix, ['id', 'Prediction']].to_csv('res.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py22",
   "language": "python",
   "name": "py22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
