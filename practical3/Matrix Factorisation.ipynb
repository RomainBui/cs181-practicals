{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import scipy.sparse as sp\n",
    "from sklearn.linear_model import Ridge\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file  = 'data/test.csv'\n",
    "df = pd.read_csv(train_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_file, header=0)\n",
    "testdf = pd.read_csv(test_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame.from_csv('data/traindf2')\n",
    "validatedf = pd.DataFrame.from_csv('data/validatedf2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uuids = df.user.unique()#unique-users\n",
    "uiids = df.artist.unique()#unique-items\n",
    "uuidmap={v:k for k,v in enumerate(uuids)}#of length U\n",
    "uiidmap={v:k for k,v in enumerate(uiids)}#of length M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ybar = traindf.plays.mean()\n",
    "global_median = traindf.plays.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "groupby_user = traindf.groupby('user')\n",
    "user_biases = dict()\n",
    "user_means = dict()\n",
    "user_medians = dict()\n",
    "user_biases_median = dict()\n",
    "for id in uuids:\n",
    "    group = groupby_user.get_group(id)\n",
    "    user_mean = group.plays.mean()\n",
    "    user_biases[id] = user_mean - ybar\n",
    "    user_means[id] = user_mean\n",
    "    user_medians[id] = group.plays.median()\n",
    "    user_biases_median[id] = group.plays.median() - global_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupby_item = traindf.groupby('artist')\n",
    "item_biases = dict()\n",
    "item_means = dict()\n",
    "item_medians = dict()\n",
    "item_biases_median = dict()\n",
    "for id in uiids:\n",
    "    group = groupby_item.get_group(id)\n",
    "    item_mean = group.plays.mean()\n",
    "    item_biases[id] = item_mean - ybar\n",
    "    item_means[id]  = item_mean\n",
    "    item_medians[id] = group.plays.median()\n",
    "    item_biases_median[id] = group.plays.median() - global_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given the initial data frame, and the number of latent factors lshape\n",
    "def design_p(indf, lshape, inps):\n",
    "    #the number of columns in the added part of the feature matrix\n",
    "    qshape=lshape*len(uuids)\n",
    "    #the number of columns we are coming in with from the previous regression\n",
    "    pshape=lshape*len(uiids)\n",
    "    #the number of features from the baseline regression\n",
    "    fshape=2\n",
    "    #userid and itemid along with star rating from the input dataframe\n",
    "    stvals=indf[['user', 'artist', 'plays']].values\n",
    "    #the design matrix of size N rows X M+U+L*U columns\n",
    "    designp=np.zeros(stvals.shape[0], dtype=object)\n",
    "    #ratings column vector of N rows\n",
    "    plays=np.zeros(stvals.shape[0])\n",
    "    #for each row in the dataframe:\n",
    "    for i, row in enumerate(stvals):\n",
    "        newrow = np.zeros(qshape + pshape)\n",
    "        #get userid, restaurant id and rating from the row\n",
    "        user=row[0]\n",
    "        artist=row[1]\n",
    "        plays[i]=row[2]\n",
    "        #use the index corresponding to the userid and L to figure how many slots\n",
    "        #in the design matrix to take up and where to take them up from\n",
    "        #for e.g., if index is 2(ie third index) and L=2,this will be from index 4 on\n",
    "        #(which is the 5th index. )\n",
    "        posq=uuidmap[user]*lshape\n",
    "        putinat=fshape+posq\n",
    "\n",
    "        #use the index corresponding to the business id to get the indexes of the incoming p\n",
    "        posp=uiidmap[artist]*lshape\n",
    "        #fill the baseline part of the design matrix in for this row\n",
    "        \n",
    "        #designp[i,:-qshape]=np.concatenate([1*(userid==uuids), 1*(bizid==uiids)])\n",
    "        newrow[:2] =[user_medians[user],item_medians[artist]]\n",
    "        #Fill L of the slots from putinat onwards to L elements from the p matrix\n",
    "        #if the index is 4(the fifth index) and L=2, this is the 8th and 9th element of the\n",
    "        #p coefficients\n",
    "        newrow[putinat:putinat+lshape]=inps[posp:posp+lshape]\n",
    "        newrow = sp.coo_matrix(newrow)\n",
    "        designp[i] = newrow\n",
    "    #return the constructed design matrix and ratings\n",
    "    return sp.vstack(designp), plays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#given the initial data frame, and the number of latent factors lshape\n",
    "def design_q(indf, lshape, inqs):\n",
    "    #the number of columns in the added part of the feature matrix\n",
    "    pshape=lshape*len(uiids)\n",
    "    #the number of columns we are coming in with from the previous regression\n",
    "    qshape=lshape*len(uuids)\n",
    "    #the number of features from the baseline regression\n",
    "    fshape=2\n",
    "    #userid and itemid along with star rating from the input dataframe\n",
    "    stvals=indf[['user', 'artist','plays']].values\n",
    "    #the design matrix of size N rows X M+U+L*U columns\n",
    "    designq=np.zeros(stvals.shape[0], dtype=object)\n",
    "    #ratings column vector of N rows\n",
    "    plays=np.zeros(stvals.shape[0])\n",
    "    #for each row in the dataframe:\n",
    "    for i, row in enumerate(stvals):\n",
    "        newrow = np.zeros(qshape + pshape)\n",
    "        #get userid, restaurant id and rating from the row\n",
    "        user=row[0]\n",
    "        artist=row[1]\n",
    "        #set the ith element of the rating vector to the rating from the matching row\n",
    "        plays[i]=row[2]\n",
    "        #use the index corresponding to the bizid and L to figure how many slots\n",
    "        #in the design matrix to take up and where to take them up from\n",
    "        #for e.g., if index is 2(ie third index) and L=2,this will be from index 4 on\n",
    "        #(which is the 5th index. )\n",
    "        posp=uiidmap[artist]*lshape\n",
    "        putinat=fshape+posp\n",
    "\n",
    "        #use the index corresponding to the userid to get the indexes of the incoming p\n",
    "        posq=uuidmap[user]*lshape\n",
    "        \n",
    "        newrow[:2] =[user_medians[user],item_medians[artist]]\n",
    "\n",
    "        #Fill L of the slots from putinat onwards to L elements from the p matrix\n",
    "        #if the index is 4(the fifth index) and L=2, this is the 8th and 9th element of the\n",
    "        #p coefficients\n",
    "        newrow[putinat:putinat+lshape]=inqs[posp:posp+lshape]\n",
    "        newrow = sp.coo_matrix(newrow)\n",
    "        designq[i] = newrow\n",
    "        \n",
    "    #return the constructed design matrix and ratings\n",
    "    return sp.vstack(designq), plays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L=1\n",
    "initps=np.random.rand(L*len(uiids))\n",
    "initqs=np.random.rand(L*len(uuids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NOTICE THE TWO ALPHAS BELOW AND READ THE EXPLANATION ABOVE\n",
    "from sklearn.metrics import mean_squared_error \n",
    "vdict2={}\n",
    "rdict2={}\n",
    "convdict={}\n",
    "maxiters=100\n",
    "alpha=1\n",
    "inps=initps\n",
    "inqs=initqs\n",
    "sums=[]\n",
    "conv=[]\n",
    "reachedit=0\n",
    "for it in range(maxiters):\n",
    "    #create design_p with inps randomly chosen\n",
    "    designp, rats=design_p(traindf.head(10000), L, inps)\n",
    "    #fit\n",
    "    regrp=Ridge(alpha=alpha).fit(designp, rats)\n",
    "    inqsold=inqs\n",
    "    inqs=regrp.coef_[-inqs.shape[0]:]\n",
    "    #use regression coefficients as the new inqs\n",
    "    designq, rats=design_q(traindf.head(10000), L, inqs)\n",
    "    regrq=Ridge(alpha=alpha).fit(designq, rats)\n",
    "    inpsold=inps\n",
    "    inps=regrq.coef_[-inps.shape[0]:]\n",
    "    #just to see how far from 0 these are\n",
    "    sums.append((inqs.sum(), inps.sum()))\n",
    "    #see if the coefficients are converging\n",
    "    pconv=mean_squared_error(inpsold, inps)\n",
    "    qconv=mean_squared_error(inqsold, inqs)\n",
    "    conv.append((pconv, qconv))\n",
    "    if it > 9 and it % 10 ==0:\n",
    "        print \"Iteration \",it, pconv, qconv\n",
    "    reachedit=it\n",
    "    if pconv < 0.005 and qconv < 0.005:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fit once more using the new inps\n",
    "designp, rats=design_p(traindf.head(10000), L, inps)\n",
    "regrp=Ridge(alpha=alpha).fit(designp, rats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226.31874280199739"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "valdesignp, validaterats = design_p(traindf.head(10000), L, inps)\n",
    "vpreds=regrp.predict(valdesignp)\n",
    "mean_absolute_error(rats, vpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now predict on the validation set\n",
    "valdesignp, validaterats = design_p(validatedf, L, inps)\n",
    "vpreds=regrp.predict(valdesignp)\n",
    "rmse=get_rmse(validaterats, vpreds)\n",
    "vdict2[a]=rmse\n",
    "rdict2[a]=regrp\n",
    "convdict[a]=(reachedit, conv, sums)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
