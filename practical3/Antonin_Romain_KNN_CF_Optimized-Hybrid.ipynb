{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import boto\n",
    "import pyprind\n",
    "from scipy import stats\n",
    "import scipy\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boto Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s3 = boto.connect_s3(aws_access_key_id='AKIAINZZJLON6MFVSKBQ', \n",
    "#                      aws_secret_access_key='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s3_bucket_p2 = s3.get_bucket('practicals3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k = s3_bucket_p2.new_key('res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "#train0 = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-9ed053baa547>\", line 1, in <module>\n",
      "    train = pd.read_csv('https://s3-us-west-1.amazonaws.com/practicals3/train.csv')\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/parsers.py\", line 498, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/parsers.py\", line 262, in _read\n",
      "    compression=kwds.get('compression', None))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/common.py\", line 266, in get_filepath_or_buffer\n",
      "    to_return = list(maybe_read_encoded_stream(req, encoding, compression)) + \\\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/common.py\", line 189, in maybe_read_encoded_stream\n",
      "    reader = StringIO(reader.read().decode(encoding, errors))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 446, in read\n",
      "    s = self._safe_read(self.length)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 592, in _safe_read\n",
      "    chunk = self.fp.read(min(amt, MAXAMOUNT))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/socket.py\", line 575, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\", line 924, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\", line 786, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\", line 570, in read\n",
      "    v = self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1877, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 970, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 233, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 267, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 1414, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 171, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tokenize.py\", line 456, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tokenize.py\", line 425, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tokenize.py\", line 383, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   3065\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-9ed053baa547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://s3-us-west-1.amazonaws.com/practicals3/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://s3-us-west-1.amazonaws.com/practicals3/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    261\u001b[0m                                                                 \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                                                 compression=kwds.get('compression', None))\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferred_compression\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'infer'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# cat on the compression to the tuple returned by the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mto_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_read_encoded_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mmaybe_read_encoded_stream\u001b[0;34m(reader, encoding, compression)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m    923\u001b[0m                   self.__class__)\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1876\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1880\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1242\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             )\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1002\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_records\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mabspath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;31m#print '*** record:',file,lnum,func,lines,index  # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('https://s3-us-west-1.amazonaws.com/practicals3/train.csv')\n",
    "test  = pd.read_csv('https://s3-us-west-1.amazonaws.com/practicals3/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = train0.loc[np.in1d(train0.artist, train0.artist.unique()[:20])] # Only use the 20 first artists\n",
    "#train = train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_artist = train.artist.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Compute the baseline\n",
    "1. Compute the Common Support as : $NCommon_{ij}$ How many users rated/played both music\n",
    "2. Compute the Rho_Correlation : $\\rho(\\bf{Y_{u_i}} - \\bf{\\overline{Y_u}} ; \\bf{Y_{u_j}} - \\bf{\\overline{Y_u}})$\n",
    "3. Compute the Similarity : $ \\frac{N_Common \\rho_{mj}}{N_Common + reg}$\n",
    "4. Apply the Central Dogma : $Y_{um} = Y_{um}^{Baseline} + \\frac{\\sum_{j \\in S^k(m)} s_{mj} (Y_{uj} - Y_{um}^{Baseline})}{\\sum_{j \\in S^k(m)} s_{mj}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Approach by filtering given u,m, don't compute all the support etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding IDs ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the speed of the various algorithm, we implement IDs instead of using the text to perform the location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_id = pd.DataFrame(columns = ['artist'])\n",
    "artist_id.loc[:, 'artist'] = train.artist.unique()\n",
    "artist_id.loc[:, 'Id'] = artist_id.index\n",
    "artist_id.index = artist_id.artist.values\n",
    "\n",
    "train.loc[:, 'artist_id'] = artist_id.loc[train.artist, 'Id'].values\n",
    "test.loc[:, 'artist_id'] = artist_id.loc[test.artist, 'Id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_id = pd.DataFrame(columns = ['user'])\n",
    "user_id.loc[:, 'user'] = train.user.unique()\n",
    "user_id.loc[:, 'Id']   = user_id.index\n",
    "user_id.index = user_id.user.values\n",
    "\n",
    "train.loc[:, 'user_id'] = user_id.loc[train.user, 'Id'].values\n",
    "test.loc[:, 'user_id']  = user_id.loc[test.user, 'Id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 : Compute the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# u    = test.loc[0, 'user_id']\n",
    "# m    = test.loc[0, 'artist_id']\n",
    "# u =0\n",
    "# m=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeBaseline(u,m,train):\n",
    "    Y_bar = train.plays.median()\n",
    "    Y_u = train.loc[train.user_id == u].plays.median()\n",
    "    Y_m = train.loc[train.artist_id == m].plays.median()\n",
    "    Y_baseline = Y_bar + Y_u - Y_bar + Y_m - Y_bar\n",
    "    return Y_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#computeBaseline(u,m,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Get the Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetSupport(u,m,train):\n",
    "\n",
    "    potential_artists = train.loc[train.user_id == u, 'artist_id'].unique()\n",
    "\n",
    "    N_support = np.empty(shape = (len(potential_artists)))\n",
    "    support = [[] for i in range(len(potential_artists))]\n",
    "    prog_bar = pyprind.ProgBar(len(potential_artists))\n",
    "\n",
    "    # Loop on the artist\n",
    "    for j,artist2 in enumerate(potential_artists):\n",
    "        prog_bar.update()\n",
    "        support[j]   = set(train.loc[(train.artist_id == m), 'user_id']).intersection(set(train.loc[(train.artist_id == artist2), 'user_id']))\n",
    "        N_support[j] = len(support[j])\n",
    "        \n",
    "    return (N_support, support, potential_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#N_support, support, base_artist = GetSupport(u,m,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 : Compute the similarity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the user average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prog_bar = pyprind.ProgBar(len(train.user.unique()))\n",
    "# user_avg = pd.DataFrame(columns=['User', 'AVG'])\n",
    "# for u in train.user_id.unique():\n",
    "#     user_avg = user_avg.append({'User': u, 'AVG' : train.loc[train.user_id == u].plays.median()}, ignore_index=True)\n",
    "#     prog_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user_avg = pd.read_csv('user_avg2.csv')\n",
    "# user_avg.index = user_avg.User.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similarity Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeSim(artist1, artist2, unique_artist, support, N_support, train_small, train, reg = 3, verbose=False):\n",
    "    commonUser = support[unique_artist.tolist().index(artist2)]\n",
    "    N_Common = N_support[unique_artist.tolist().index(artist2)]\n",
    "    user_artist1 = []\n",
    "    user_artist2 = []\n",
    "    if(verbose):\n",
    "        prog_bar = pyprind.ProgBar(len(commonUser))\n",
    "    \n",
    "    ix_artist1 = (train.artist_id == artist1)\n",
    "    ix_artist2 = (train.artist_id == artist2)\n",
    "    \n",
    "    for i in commonUser:\n",
    "        #print(i, end = \",\")\n",
    "        if(verbose):\n",
    "            prog_bar.update()\n",
    "        u_avg = train.loc[train.user_id == i].plays.median()\n",
    "        user_artist1.append(int(train_small.loc[(train_small.user_id == i) & ix_artist1].plays) - u_avg)\n",
    "        user_artist2.append(int(train_small.loc[(train_small.user_id == i) & ix_artist2].plays) - u_avg)\n",
    "        \n",
    "    rho = scipy.stats.pearsonr(user_artist1, user_artist2)[0]\n",
    "    rho_shrunk = N_Common * rho / (N_Common + reg) \n",
    "    return((1-rho_shrunk)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sim = np.empty(shape = (len(base_artist)))\n",
    "# artist1 = m\n",
    "# prog_bar = pyprind.ProgBar(len(base_artist))\n",
    "\n",
    "# #train_small\n",
    "# ix = np.in1d(train.artist_id, np.append(m, base_artist))\n",
    "# train_small = train.loc[ix]\n",
    "\n",
    "# for j,artist2 in enumerate(base_artist):\n",
    "#     sim[j] = computeSim(artist1, artist2, base_artist, support, N_support,train_small, train)\n",
    "#     prog_bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 : Adjust the Baseline - Get the Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #input:\n",
    "# k = 3\n",
    "\n",
    "# res = pd.DataFrame(columns = ['artist_id', 'sim'])\n",
    "# res.loc[:, 'artist_id'] = base_artist\n",
    "# res.loc[:, 'sim'] = sim\n",
    "# res = res.sort_values(by = 'sim', ascending = False)\n",
    "\n",
    "# # Apply the final Algo\n",
    "# num = 0\n",
    "# denom = 0\n",
    "# Yum_base = computeBaseline(u, m, train)\n",
    "\n",
    "# for i in res.index[:k]:\n",
    "#     Yuj = int(train[(train.user_id == u) & (train.artist_id == res.loc[i, 'artist_id'])].plays)\n",
    "#     num += res.loc[i, 'sim']*(Yuj-Yum_base)\n",
    "#     denom += res.loc[i, 'sim']\n",
    "\n",
    "# Y_um = Yum_base + num/denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakePrediction(u,m,train,k=5):\n",
    "    # Compute Support\n",
    "    print('Compute Support')\n",
    "    N_support, support, base_artist = GetSupport(u,m,train)\n",
    "\n",
    "    # Compute the sim\n",
    "    print('Compute Sim')\n",
    "    sim = np.empty(shape = (len(base_artist)))\n",
    "    artist1 = m\n",
    "    prog_bar = pyprind.ProgBar(len(base_artist))\n",
    "\n",
    "    #train_small\n",
    "    ix = np.in1d(train.artist_id, np.append(m, base_artist))\n",
    "    train_small = train.loc[ix]\n",
    "\n",
    "    for j,artist2 in enumerate(base_artist):\n",
    "        sim[j] = computeSim(artist1, artist2, base_artist, support, N_support,train_small, train)\n",
    "        prog_bar.update()\n",
    "        \n",
    "    #input:\n",
    "#    k = 5\n",
    "\n",
    "    res = pd.DataFrame(columns = ['artist_id', 'sim'])\n",
    "    res.loc[:, 'artist_id'] = base_artist\n",
    "    res.loc[:, 'sim'] = sim\n",
    "    res = res.sort_values(by = 'sim', ascending = False)\n",
    "\n",
    "    # Apply the final Algo\n",
    "    print('Apply Final Algo')\n",
    "    num = 0\n",
    "    denom = 0\n",
    "    Yum_base = computeBaseline(u, m, train)\n",
    "\n",
    "    for i in res.index[:k]:\n",
    "        Yuj = int(train[(train.user_id == u) & (train.artist_id == res.loc[i, 'artist_id'])].plays)\n",
    "        num += res.loc[i, 'sim']*(Yuj-Yum_base)\n",
    "        denom += res.loc[i, 'sim']\n",
    "\n",
    "    Y_um = Yum_base + num/denom\n",
    "    \n",
    "    return Y_um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_res = pd.DataFrame(columns = ['Id', 'Prediction'])\n",
    "count = 0\n",
    "\n",
    "for r in test.iterrows():\n",
    "    print('*********' + str(r[1]['Id']) + '*********')\n",
    "    temp = MakePrediction(r[1]['user_id'], r[1]['artist_id'], train)\n",
    "    final_res = final_res.append({'Id':r[1]['Id'], 'Prediction' :temp}, ignore_index = True)\n",
    "    \n",
    "    count += 1\n",
    "    if (count == 100):\n",
    "        print('done')\n",
    "        count = 0\n",
    "        final_res.to_csv('res.csv', index = False)\n",
    "        k.set_contents_from_filename('res.csv')\n",
    "        \n",
    "#print(\"Saving\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test.artist_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train.artist_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction with Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load the Data\n",
    "user_avg = pd.read_csv('Data/EC2/user_avg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the Item Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:26\n"
     ]
    }
   ],
   "source": [
    "prog_bar = pyprind.ProgBar(len(train.artist_id.unique()))\n",
    "artist_avg = pd.DataFrame(columns=['Artist', 'AVG'])\n",
    "for m in train.artist_id.unique():\n",
    "    artist_avg = artist_avg.append({'Artist': m, 'AVG' : train.loc[train.artist_id == m].plays.median()}, ignore_index=True)\n",
    "    prog_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_bar = train.plays.median()\n",
    "def computeBaseline2(u,m,user_avg,artist_avg,Y_bar):\n",
    "    Y_u = user_avg.loc[u, 'AVG']\n",
    "    Y_m = artist_avg.loc[m, 'AVG']\n",
    "    Y_baseline = Y_bar + Y_u - Y_bar + Y_m - Y_bar\n",
    "    return Y_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computeBaseline2(u,m,user_avg,artist_avg,y_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_res = []\n",
    "count = 0\n",
    "my_bar = pyprind.ProgBar(test.shape[0])\n",
    "y_bar = train.plays.median()\n",
    "\n",
    "for r in test.iterrows():\n",
    "    my_bar.update()\n",
    "    #print('*********' + str(r[1]['Id']) + '*********')\n",
    "    temp = computeBaseline2(r[1]['user_id'], r[1]['artist_id'],user_avg,artist_avg,y_bar)\n",
    "    final_res.append(temp)\n",
    "    #final_res = final_res.append({'Id':r[1]['Id'], 'Prediction' :temp}, ignore_index = True)\n",
    "    \n",
    "#     count += 1\n",
    "#     if (count == 100):\n",
    "#         print('done')\n",
    "#         count = 0\n",
    "#         final_res.to_csv('res_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_res[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns = ['Id', 'plays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.loc[:, 'Id'] = test.Id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.loc[:,'plays'] = final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.loc[res.plays<0, 'plays'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.to_csv('res_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "1. Use the NSupport, and the Support precomputed\n",
    "2. Create a matrix of the top Artist that will be used to scale down the basis of the artist used to compute the sim\n",
    "3. Apply the classical algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_avg = pd.read_csv('Data/EC2/user_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "support = np.load('Data/EC2/support.npy', encoding = 'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_support = np.load('Data/EC2/Nsupport.npy', encoding = 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rank the artists by their number of unique views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_rank = train.artist_id.value_counts()\n",
    "train.loc[:, 'Popularity_Index'] = train.artist_id.apply(lambda x : artist_rank[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_rank = train.user_id.value_counts()\n",
    "#train.loc[:, 'UserPopularity_Index'] = train.user_id.apply(lambda x : user_rank[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "u = test.loc[0]['user_id']\n",
    "m = test.loc[0]['artist_id']\n",
    "\n",
    "artist1 = m\n",
    "artist2 = 12\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeSim(artist1, artist2, support, N_support, user_avg, user_rank, train, reg = 3, nb_common_user = 10):\n",
    "    \n",
    "    commonUser = support[artist1][artist2]\n",
    "    # Only keep the 10 most popular user\n",
    "    commonUser = user_rank[commonUser].sort_values(ascending = False).index[:nb_common_user]\n",
    "    \n",
    "    #N_Common = N_support[artist1][artist2]\n",
    "    N_Common = len(commonUser)\n",
    "    user_artist1 = []\n",
    "    user_artist2 = []\n",
    "    \n",
    "    ix_artist1 = train.artist_id == artist1\n",
    "    ix_artist2 = train.artist_id == artist2\n",
    "    \n",
    "    for i in commonUser:\n",
    "        u_avg = user_avg.loc[i,'AVG']\n",
    "        user_artist1.append(int(train.loc[(train.user_id == i) & ix_artist1].plays) - u_avg)\n",
    "        user_artist2.append(int(train.loc[(train.user_id == i) & ix_artist2].plays) - u_avg)\n",
    "    rho = scipy.stats.pearsonr(user_artist1, user_artist2)[0]\n",
    "    rho_shrunk = N_Common * rho / (N_Common + reg) \n",
    "    return((1-rho_shrunk)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_artist = train.loc[train.user_id == u, ['artist_id', 'Popularity_Index']].sort_values(by = 'Popularity_Index', ascending = False).artist_id[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply the Basic Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MakePrediction(user, artist, base_artist, support, N_support, user_avg, user_rank, artist_avg, Y_bar, train):\n",
    "\n",
    "    u = user \n",
    "    m = artist\n",
    "    \n",
    "    # Compute the sim\n",
    "    sim = np.empty(shape = (len(base_artist)))\n",
    "    #prog_bar = pyprind.ProgBar(len(base_artist))\n",
    "\n",
    "    #train_small\n",
    "    # ix = np.in1d(train.artist_id, np.append(m, base_artist))\n",
    "    # train_small = train.loc[ix]\n",
    "\n",
    "    for j,artist2 in enumerate(base_artist):\n",
    "        sim[j] = computeSim(artist1, artist2, support, N_support, user_avg, user_rank, train)\n",
    "        #prog_bar.update()\n",
    "\n",
    "    #input:\n",
    "    k = 5\n",
    "\n",
    "    res = pd.DataFrame(columns = ['artist_id', 'sim'])\n",
    "    res.loc[:, 'artist_id'] = base_artist\n",
    "    res.loc[:, 'sim'] = sim\n",
    "    res = res.sort_values(by = 'sim', ascending = False)\n",
    "\n",
    "    # Apply the final Algo\n",
    "    num = 0\n",
    "    denom = 0\n",
    "    Yum_base = computeBaseline2(u,m,user_avg, artist_avg, Y_bar)\n",
    "\n",
    "    for i in res.index[:k]:\n",
    "        Yuj = int(train[(train.user_id == u) & (train.artist_id == res.loc[i, 'artist_id'])].plays)\n",
    "        num += res.loc[i, 'sim']*(Yuj-Yum_base)\n",
    "        denom += res.loc[i, 'sim']\n",
    "\n",
    "    Y_um = Yum_base + num/denom\n",
    "\n",
    "    return Y_um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[                              ]"
     ]
    }
   ],
   "source": [
    "final_res = pd.DataFrame(columns = ['Id', 'Prediction'])\n",
    "count = 0\n",
    "my_bar = pyprind.ProgBar(test.shape[0])\n",
    "\n",
    "for r in test.iterrows():\n",
    "    #print('*********' + str(r[1]['Id']) + '*********')\n",
    "    base_artist = train.loc[train.user_id == r[1]['user_id'], ['artist_id', 'Popularity_Index']].sort_values(by = 'Popularity_Index', ascending = False).artist_id[:5]\n",
    "    temp = MakePrediction(r[1]['user_id'], r[1]['artist_id'], base_artist, support, N_support, user_avg, user_rank, artist_avg, y_bar, train)\n",
    "    final_res = final_res.append({'Id':r[1]['Id'], 'Prediction' :temp}, ignore_index = True)\n",
    "    my_bar.update()\n",
    "    \n",
    "    count += 1\n",
    "    if (count == 100):\n",
    "        print('done')\n",
    "        count = 0\n",
    "        final_res.to_csv('res.csv', index = False)\n",
    "        #k.set_contents_from_filename('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
